services:
  # vLLM LLM Services (Brain)
  llm:
    image: thor_vllm_container:25.08-py3-base
    container_name: oo1_llm
    ipc: host
    network_mode: host
    runtime: nvidia
    privileged: true
    user: "0:0"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_PATH=Qwen/Qwen3-8B-AWQ
      - VLLM_DISABLED_KERNELS=MacheteLinearKernel
      - VLLM_ATTENTION_BACKEND=FLASH_ATTN
    volumes:
      - ./models:/models
      - ./logs/llm:/workspace/logs
      - ./services/llm:/workspace/llm:ro
    ports:
      - "8000:8000"
    shm_size: 16gb
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    restart: unless-stopped
    working_dir: /workspace
    command: bash /workspace/llm/start_llm.sh

  # Faster-Whisper ASR Service (Ears) - DISABLED TEMPORARILY
  # faster-whisper:
  #   image: dustynv/faster-whisper:r36.4.0-cu128-24.04
  #   container_name: oo1_asr
  #   runtime: nvidia
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=0
  #     - CUDA_VISIBLE_DEVICES=0
  #   volumes:
  #     - ./logs/asr:/workspace/logs
  #     - ./services/asr:/workspace/asr:ro
  #   ports:
  #     - "8003:8003"
  #   networks:
  #     - oo1_network
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 60s
  #   restart: unless-stopped
  #   working_dir: /workspace
  #   command: python3 /workspace/asr/start_asr.py

  # XTTS TTS Service (Mouth) - DISABLED TEMPORARILY
  # xtts:
  #   image: dustynv/xtts:r36.3.0
  #   container_name: oo1_tts
  #   runtime: nvidia
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=0
  #     - CUDA_VISIBLE_DEVICES=0
  #     - TTS_LANGUAGE=zh
  #     - TTS_PORT=8004
  #   volumes:
  #     - ./logs/tts:/workspace/logs
  #     - ./voices:/workspace/voices
  #     - ./services/tts:/workspace/tts:ro
  #   ports:
  #     - "8004:8004"
  #   networks:
  #     - oo1_network
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 120s
  #   restart: unless-stopped
  #   working_dir: /workspace
  #   command: python3 /workspace/tts/start_tts.py

networks:
  oo1_network:
    driver: bridge

volumes:
  llm_cache:
    driver: local
